精确的车辆分类和跟踪对于智能交通系统（ITS）和利用精确位置智能的规划

#### 存在问题：
P1.需要大的训练数据集：创建一个训练数据集，该数据集包含来自现有摄像机的近30，000个样本，包含七类车辆。提供数据集作为对这项研究的贡献。
P2.域偏移问题：在几个最先进的YOLO网络上训练和应用了基于迁移学习的微调。
P3.将实时多车辆跟踪算法与DL耦合：提出一种多车辆跟踪算法，该算法实时获得车辆的每车道计数、分类和速度。

实验表明，精确度在微调后翻了一番（71%对30%）。基于对四个YOLO网络的比较，将YOLOv5-large网络与我们的跟踪算法相结合，可以在总体准确度（95%与高达90%）、损失（0.033与高达0.036）和模型大小（91.6 MB与高达120.6 MB）之间进行权衡。

主要工作： 
1.比较了DL现有的SOTA网络用于实时车辆检测和分类。
2.在基于迁移学习的微调帮助下，我们最小化了DL网络所遭受的域偏移的影响。
3.我们创建并提供了七个车辆类别的车辆分类数据集。
4.我们提出了一种多车辆跟踪算法，该算法可以获得基于车道的统计数据，如计数、速度和平均速度沿着车辆分类

##### 背景:
YOLO v1:统一了特征提取、对象定位和分类等方法，形成单阶段架构。该网络在平均平均精度（mAP）方面是SOTA，检测速度快。
YOLO v2:  消除了 YOLOv1 末尾的全连接层，允许网络独立于图像分辨率运行。
YOLOv3:  能够生成类似的 mAP
基于 YOLOv2 的改进检测模型，该模型使用 k-means++ 算法来训练数据集以聚类车辆边界框。为了改善不同规模的车辆造成的损失，引入了归一化。此外，删除了重复的卷积层以改善特征提取。
使用 YOLOv3 网络（YOLOv2 的改进版本）实时检测车辆和交通信号灯，方法是使用名为车辆和交通灯数据集 （V-TLD） 的新型高质量数据集以平衡的速度和精度检测小物体。
使用 YOLOv3 来检测和分类车辆，并使用 ORB 算法来获取行驶方向。
使用经过微调的YOLOv4使用UA-DETRAC数据集进行车辆检测，这比以前的迭代更快。
MOT的单相机跟踪技术，该技术允许检测视频帧序列中的多个对象。这种类型的跟踪性能取决于检测和遮挡的质量，因为单个相机提供单侧视图。由于这些因素导致的检测问题已被DL模型最小化，该模型可以检测具有部分遮挡的物体，这意味着，如果物体没有被较大的物体完全隐藏，最近的CNN仍然可以预测物体。在实时MOT中使用的一些DL网络包括Faster-RCNN SSD和YOLO。
传统的跟踪方法中，首先在初始帧中检测对象，然后在区域中搜索特征以在随后的图像序列中匹配它们
传统的检测器，如基于轮廓的目标检测，哈里斯角检测器，SIFT和基于特征点的方法，用于产生错误检测，导致进一步的错误匹配。然而，使用DL模型检测物体，然后使用传统的跟踪方法匹配特征，从而提高了性能。

在尝试使用来自新添加的摄像头的新视频流检测车辆时，在从各种来源收集的大型训练数据集上训练的网络仍然表现不佳。此问题通常称为域移位问题，

### 方法
该方法引入了一种基于微调神经网络的车辆检测算法，将检测到的车辆实时分类为七类（汽车、公共汽车、出租车、自行车、皮卡、卡车和拖车）之一，对道路上每条车道上的分类车辆进行计数，跟踪每辆车的运动，测量单个车辆的速度，并计算不同时间范围内的平均速度。

用4G / 5G宽带技术从道路监控摄像机收集视频流。使用实时流协议 （RTSP） 将视频流式传输到具有高处理能力的计算服务器，在该服务器中注册流，并绘制多边形以描绘每条车道。注册摄像头流和车道后，预先训练的深度学习模型将检测、分类和跟踪进入车道多边形的车辆。这种多车辆跟踪算法生成每辆车在每条车道上的计数、分类和计算速度，然后根据来自车道的信息计算不同时间范围内的平均速度以及车辆的机动性。

![[Pasted image 20230228094832.png]]![[Pasted image 20230228095910.png]]
训练数据集：
- TR1由从监控视频中收集的大量训练样本组成，用于训练基本模型 M1，该模型经过大量步骤训练
-   TR2 由在整个系统实施期间从高速公路上使用的摄像头收集的少量样本组成，以使用从 M2 转移的基本知识训练微调的 M1 型。

![[Pasted image 20230301085513.png]]

##### 基于 YOLO 的检测和分类
区别在于网络宽度和深度的扩展乘数
在 YOLOv3中，使用具有批量归一化和泄漏 ReLU 激活的 DarkNet-53 骨干，在没有完全连接层的情况下提取特征，首先从图像中准备特征图。在特征图上绘制一个 13 × 13 网格，用三个不同比例的边界框预测对象，最终合并。并集交点最高 （IoU） 的框是预测。分别使用浅层和深层要素检测小型和大型物体。
YOLOv5颈部是一系列不同的层，它们混合并组合了来自骨干的图像特征，以便向前传递以进行预测。头部从脖子上获取特征和边界框，以进行最终的类预测步骤。
![[Pasted image 20230302094318.png]]

为了评估 YOLO 网络，我们对损失函数使用了改进的并集交集 （IoU），即广义并集交集 （GIoU）
![[Pasted image 20230302094354.png]]
 A 和 B 分别是地面真值和预测的边界框，C 是 A 和 B 之间的最小矩形，IoU 是 A 和 B 的交点。
GIoU 的主要改进是它定义了最小封闭区域 C，使得 A 和 B 的边界包含在 C 中。然后，GIoU 计算 C 中未包含的 A 和 B 的面积与 C 的总面积成比例。

#### 基于迁移学习的微调
在训练的第二阶段，在 TR2 上训练了与以前相同的模型架构，但权重是从先前训练的模型初始化的。
#### 摄像头注册和道路投资回报率选择
相机需要面向车道，与最低点成 40 到 50° 的角度。摄像机的最佳高度可以从用于产生TR2的视频流中确定。摄像机连接到4G / 5G宽带网络，将视频流式传输到运行基于训练的YOLO模型的监视系统的计算机服务器。服务器可以使用注册到相机 ID 的唯一 RTSP 链接来定位相机流。 在流的图像帧上手动绘制车道，以便以米为单位测量与交通流平行的多边形两侧的长度，以米为单位计算车辆的速度。然后为车道多边形提供车道 ID，从而完成摄像机流和车道的注册。注册相机流和通道后的下一步是调整视频帧的大小。减少了可能导致检测性能不佳的图像数据丢失。
#### 带速度检测的多车辆跟踪
训练 YOLO 模型并收集/注册摄像头流后的下一步是使用训练后的模型跟踪实时视频流上的各个车辆类别。一种基于质心跟踪的多车辆跟踪算法，该算法从任何 DL 模型中获取预测的类和边界框，并执行多项任务来跟踪车辆，计算每个类别的车辆数量，并计算道路每个车道多边形的速度。此方法在计算能力、速度和匹配成本方面表现出卓越的性能。
第一步是使用训练好的模型检测车辆类别，并在注册的视频流上获取检测到的车辆的边界框。此边界框和车道多边形及其 ID 将传递到我们的多车辆跟踪算法中。
-   计算边界框的质心，并检查质心是否落在视频流中任何已注册的车道多边形内。
    
    （一）否则，将被拒绝/取消注册，这意味着车辆类别和边界框已存储，但不通过跟踪过程。
    
    （二）如果是，则检查过滤后的车辆是否与先前图像帧中检测到的任何现有车辆匹配。
    
    -   如果不是（车辆是新车辆），则首先使用新的车辆 ID 注册它，然后传递到将功能更新到车辆 ID 的步骤。
        
    -   如果是（车辆存在），则直接传递到将要素更新为车辆 ID 的步骤。
        
    
-   将以下要素更新为车辆 ID：车辆 ID、车辆进入的车道、首次进入车道面的影像框上车辆质心的坐标、进入时间、车辆质心的最新坐标以及车辆的计算速度。计算以下内容：
    
    （一）距离：进入车道多边形的最新质心和第一个质心的坐标之差。使用之前在注册车道时提供的参考长度将距离转换为米。
    
    （二）  时间：首次在车道多边形内记录车辆的时间差与当前记录的时间差。
    
    （三）速度 ：= 距离/时间
    
-   将车辆 ID 释放为现有车辆，以便与即将推出的车辆匹配。
    
-   根据步骤 2 中的功能，准备每条车道的报告，包括班级计数、不同时间范围内的平均速度以及根据车道 ID 的车辆移动性。

第一级训练的实验结果及其由于域转移而失败的结果

YOLOv5l产生了最高的mAP_50，其次是YOLOv5s，YOLOv3和YOLOv3t。
YOLOv3模型的分类损失似乎低于YOLOv5模型，YOLOv3网络的损失最小。所有四个模型的总损失值均低于可接受的范围0.05。
![[Pasted image 20230302105619.png]]


![[Pasted image 20230302105849.png]]显示了七类汽车、公共汽车、出租车、自行车、皮卡、卡车和拖车七类中每类的预测 AP 与 TR1 数据集中提供的验证数据集的分布。YOLOv5l 表现出最高的性能。
训练四个网络的显着区别在于训练时间。最快的训练模型是 YOLOv3t，mAP_50最低，最慢的训练模型是 YOLOv3，mAP_50第二低。YOLOv5s和YOLOv5l的训练速度分别比YOLOv3快近四倍和两倍。通过比较，观察到 YOLOv5s 模型在 mAP 和训练时间方面都优于 YOLOv3。另一方面，YOLOv5l 显示了mAP_50、分类损失和训练速度之间的最佳权衡。

![[Pasted image 20230302111457.png]]![[Pasted image 20230302111512.png]]为了尽量减少域转移的影响，我们使用迁移学习将四个 TR1 训练的 YOLO 网络微调到 TR2 数据集中。代表了 YOLO 模型在微调调整后的性能。该表还显示了四个训练网络的分类损失、训练时间和大小。分类损失似乎低于期望的阈值 0.05;但是，这一次，YOLOv3 版本显示出比 YOLOv5 版本更好的性能。
微调后的模型显示出准确性的显着提高;但是，在检测、计数和跟踪方面还有更大的改进空间。
**![[Pasted image 20230302112556.png]]

实时流的速率是用整体方法可以处理的每秒帧数 （FPS） 与通过 RTSP 获得的相机流的 FPS 的比率来测量的。如果流和处理的 FPS 匹配，则处理被视为实时处理。
![[Pasted image 20230302140612.png]]

![[Pasted image 20230302142632.png]]

在适当的光强度下，使用干净、低噪声的摄像头在白天的车辆检测和计数性能最为有效。在夜间，检测效果最差。




用4G / 5G宽带技术从道路监控摄像机收集视频流。使用实时流协议 （RTSP） 将视频流式传输到具有高处理能力的计算服务器，在该服务器中注册流，并绘制多边形以描绘每条车道。注册摄像头流和车道后，预先训练的深度学习模型将检测、分类和跟踪进入车道多边形的车辆。
l训练数据集

    通过在两个层面上进行了训练，减少域偏移的影响。

  从监控视频中收集的大量训练样本组成，用于训练基本模型M1

  在系统实施期间从高速公路上使用的摄像头收集的少量样本组成，以使用从 M2 转移的基本知识训练微调的 M1 型
 l基于质心跟踪的多车俩跟踪算法 

   从DL模型中获取边界框，计算质心，检查车辆是否匹配，跟新车辆并释放
   
-   TR1 由从监控视频中收集的大量训练样本组成，用于训练基本模型 M1，该模型经过大量步骤训练。
    
-   TR2 由在整个系统实施期间从高速公路上使用的摄像头收集的少量样本组成，以使用从 M2 转移的基本知识训练微调的 M1 型。 


