等放假了，你抽空也看一看这个软件，好配置不。
https://zhuanlan.zhihu.com/p/38350957

### ViT
ViT是一种基于自注意力机制的图像分类模型，全称为Vision Transformer。是目前最先进的图像分类模型之一。

  
ViT是一种用于图像分类的深度学习模型，它可以自动学习如何从图像中提取特征，并将其用于分类任务。与传统的卷积神经网络(CNN)不同，ViT使用自注意力机制来实现特征提取，这使得它可以在不依赖于CNN的情况下很好地处理图像。ViT被认为是一种非常先进的图像分类模型，已经在许多计算机视觉任务中取得了显著的成果。



ViT的实现原理可以简单概括为以下几个步骤：

1.  输入图像被划分为一系列的小方块或补丁(patch)。
2.  每个补丁被拉成一个向量，并通过一个线性变换映射到一个较高的维度。
3.  这些向量被输入到一个Transformer编码器中，用于学习特征表示。
4.  Transformer输出的特征向量被输入到一个线性分类器中，用于进行分类。 最通俗的讲解教程如下： ViT将图像划分为很多小的方块，在每个方块中提取出特征，并将这些特征转换为向量。这些向量通过一个叫做Transformer编码器的模型进行处理，该模型可以学习如何计算不同的特征之间的关系。Transformer编码器对每个向量进行自注意力计算，即计算每个向量与其他向量之间的相似性，然后对它们加权求和，得到一个新的向量。这个新的向量包含了与之相关的所有特征信息。最后，这些向量被输入到一个线性分类器中，用于进行分类。 这种方法的好处是，它可以避免卷积神经网络中需要通过卷积核和池化层进行手动特征提取的过程。相反，ViT可以自动学习如何从图像中提取特征，并将其用于分类任务。这使得ViT能够在更广泛的任务上表现良好，包括视觉问答、图像生成等。