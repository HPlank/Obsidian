官方版的YOLOv7相同体量下比YOLOv5精度更高，速度快120%（FPS），无论是速度或是精度，YOLOv7都超过了目前已知的检测器，并且在GPU V100上进行测试， 精度为56.8% AP的模型可达到30 FPS（batch=1）以上的检测速率，与此同时，这是目前唯一一款在如此高精度下仍能超过30FPS的检测器。
为什么会这么快呢？目的是为了做到在边缘设备上做推理！

解决方式：

GPU/NPU边缘架构: 在本文中，作者提出的实时目标探测器能够更好地支持边缘移动端GPU设备和高算力GPU设备。如Apple神经引擎，Jetson AI边缘设备（Nvidia），边缘TPU（Google）等特别是近几年来，实时探测器处在大力适配边缘设备的潮流中。实时探测器的发展主要集中在高效的结构设计上。

CPU边缘架构: 对于可以在CPU上使用的实时探测器，骨干设计主要基于MobileNet、Shufflenet或Ghostnet。

高算力GPU/NPU：另一些主流的实时检测器是为GPU开发的，它们主要使用ResNet、DarkNet或DLA，然后借鉴CSPNet中的跨级策略来优化架构。

Bag-of-freebies: 除了架构优化外，作者提出的方法还集中在训练过程的优化，以提高检测器的准确性，但不增加推理耗时。


主要讲解yolov7中几个比较重要的方法，主要是为了更好的理解yolov7  中提出得几个更好的创新点， 我主要通过yolov7得论文，结合源码和网上一些别的参考资料做出讲解。

源码中的体现方式
## Extended effificient layer aggregation networks 扩展高效层聚合网络
在yolov4和v5的基础上从深度和宽度缩放

![[Pasted image 20230418232833.png]]
根据图中所示，如果前一个模块传入的是2c通道的特征图，他会先得到c个通道的特征，传到最下方用于拼接，再得到c通道个特征用于拼接。同时c通道的特征也再次传给另外两个3 * 3的卷积得到c通道的输出用于拼接，并且第三个c通道的输出也会传给右边的两个卷积，得到c通道的输出用于拼接，最终把4c通道的特征拼接起来，再传给一个1 * 1 的卷积最后得到c通道的输出

![[Pasted image 20230419000114.png]]


当输入图片依次通过前四个卷积层得到128个通道后，就要经过第一个ELAN模块

![[Pasted image 20230419001024.png]]
第四层的输入是-1，表示前一层也就是来自第三层的输出，第五层的输入是-2也表示对应的第三层的输出，同理后面的输入为-1对应它上一层的输出
第十层是一个concat拼接层，分别来自- 1 -3 -5 -6 对应的第 9 7 5 4层的输出，把他们拼接完后把他们传给一个1 * 1的卷积，所以最后画出来就对应图中11层 以上为ELAN结构
 

与论文中所对应的c partial c 两个c通道用于后续的拼接，其实就是各自通过了一个1 * 1 的卷积把通道数减半，右边的3 * 3  卷积输入输出的通道数不变，对应上面所述流程。这就是ELAN

![[Pasted image 20230419082545.png]]

 E-ELAN ：Extended ELAN 扩展的ELAN
知识回顾：
分组卷积与标准卷积的区别
对于尺寸为 H 1 x W1 x C1的输入矩阵，当标准卷积核的尺寸为h1 x w1 x C1，共有C2个标准卷积核时，标准卷积会对完整的输入数据进行运算，最终得到的输出矩阵尺寸为 H2 x W2 x C2.这里我们假设卷积运算前后的特征图尺寸保持不变，则上述过程可以展示为
![[Pasted image 20230419083034.png]]


![[Pasted image 20230419083330.png]]
分组卷积则是针对这一过程进行了改进。分组卷积中，通过指定组数 g 来确定分组数量，将输入数据分成g组。需要注意的是，这里的分组指的是在深度上进行分组，输入的宽和高保持不变，即将每个通道的数据分为一组。因为输入数据发生了改变，相应的卷积核也需要进行对应的变化，即每个卷积核的输入通道数也就变为了，而卷积核的大小是不需要改变的。同时，每组的卷积核个数也由原来的 C变为。对于每个组内的卷积运算，同样采用标准卷积运算的计算方式这样就可以得到 g 组尺寸为 H，x W，x的输出阵，最终将这 g 组输出阵进行拼接就可以得到最终的结果。这样拼接完成后，最终的输出尺寸就可以保持不变，仍然是 Hx W。x C2。分组卷积的运算过程如 图2 所示

![[Pasted image 20230419083840.png]]

上图中对于3 * 3的分组卷积，它的输入是2c通道，输出是2c，分组卷积的组数是2，它可以等价为左图中的上半部分。前C个特征图和左边的卷积做运算，后c个特征图和右边的卷积做运算，最后得到2c个输出
我们可以看出，尽管经过很多层运算，但是所有红色部分的运算和所有绿色部分的运算是隔开的，所以左边的路径可以拆成右边两条各自独立的路径，他们完全等价
![[Pasted image 20230419085144.png]]

![[Pasted image 20230419085359.png]]

如右图为yolov7配置文件中所使用的网络结构，就是把左边的结构复制一份进行分离，利用两个并行的ELAN产生两个输出，然后再把两个输出相加，最终得到c通道的输出。这里的相加操作被写成了shortcut
![[Pasted image 20230419085923.png]]![[Pasted image 20230419090028.png]]

 
![[Pasted image 20230419090834.png]]
![[Pasted image 20230419090907.png]]
	左图为放缩前的ELAN，右图为扩大了一次的的ELAN，区别是右图额外多了一条由两个卷积构成的支路，表示扩大了模型的深度，第二点是输入特征的数量，concat拼接层的数量，以及用于过渡的卷积层输出的通道数变为了原来的1.25倍， 表示扩大了模型的宽度，这就是yolov7中的复合缩放方法，在扩大深度的同时扩大宽度，放大后的模型更复杂，但是精度更高从而用于不同的使用场景   
	
计划的重参数化卷积：它最大的贡献是把重参数化卷积应用到了残差模块，或者应用到基于拼接的模块中去
知识回顾：重参数化卷积
![[Pasted image 20230419091939.png]]
RepVGG (CVPR-2021)：Reparam(3x3) = 3x3-BN + 1x1-BN + BN。对每个3x3卷积，在训练时给它构造并行的恒等和1x1卷积分支，并各自过BN后相加。我们简单堆叠这样的结构得到形成了一个VGG式的直筒型 架构。推理时的这个架构仅有一路3x3卷积夹ReLU，连分支结构都没有，因此效率很高。
在训练是三个支路通过各自的边层之后相加在传给激活函数，因此这一部分就是一个重参数化的过程，它能够在训练是使用相对复杂的结构进行训练，训练完成后重参数化成相对简单的普通卷积做推断，因此能够在不断增加推理速度的同时提升模型的训练效果
  
yolov7作者发现虽然重参数卷积已经实现了很好的效果，但是当我们直接应用到resNet和DenseNet这种带有残差模块的结构时，他的精度却大大降低。

![[Pasted image 20230419092653.png]]
（a）中没有残差模块可以直接使用RepConv进行替换 
（c）中resNet中本来有恒等连接，如果继续使用重参数进行恒等连接会造成冲突
（h）中使用RepConvN表示在RepConv的基础上去掉了恒等连接，因此不会和旁边起冲突
结论：当一个卷积层带有残差或是带有拼接的时候，它被替换成为重参数化卷积时不应该具备恒等连接
源码中的使用
![[Pasted image 20230419093828.png]]
用到了三个最基础的重参数化卷积，并没有在残差模块或拼接模块进行使用

### 标签分配方法

Deep supervision深度监督
	深度监督指的时在模型训练过程中除了最终的检测头外，给他的中间层也增加一些辅助的检测头，辅助检测头也会参与损失函数的计算，并且会反向传播，并且协助前面的层区分参数，为了区分辅助头和原来的检测头就给他们命名为lead head和aux head这种使用辅助头来进行深度监督训练的方法
标签分配：
标签分配是指把输入图片中的标注框和最终的预测值给对应起来 ，便于最后求损失值
![[Pasted image 20230420143906.png]]
目标检测的检测头一般会在网格的每个位置产生最终的预测值，再求每个网格的损失值时，除了有预测之外，还需要有目标值，假如标注框中心点的坐标时5.3 3.2 ，这个格子的目标值对应红框所表示的待检测目标，因此这个格子出有了预测值和目标值，就可以在这个位置利用损失函数求损失值，中心点不是在格子的最中间位置，在往左上角偏移，所以这个目标框同时也作为左边格子和上边格子的目标值，也就是说这个标注框同时分配给了这三个位置，这种标签分配方法就叫做硬标签，他直接根据ground truth标注框来产生每个格子的标签
![[Pasted image 20230419095346.png]]
软标签的分配方法最大的特点就是不在只通过这个标注框的中心点所在的位置就把标注框给分配好了，而是让不同的网格位置和红色的标注框进行额外的复杂运算才最终确定这个标注框的分配位置
软标签的分配方法中head 产生的预测框和标注框一起被传给分配器后才会得到每个网格位置的目标值，利用这里的软标签和预测值一起在传入到损失函数中去求损失值
![[Pasted image 20230419095722.png]]分配器
![[Pasted image 20230419095956.png]]
yolov7中使用lead head和辅助头涉及到软标签的分配，常规的思路就是各自求软标签和损失值 ,yolov7提出了两种新的方法，第一种方法叫做（lead guided assigner ）lead引导的标签分类器 ，他的含义就是辅助头在求损失值的时候，直接利用lead head产生的软标签来进行损失值的计算而不在单独去计算自己的软标签  第二中方法是在左边的基础上产生了coarse标签和fine标签这两种标签，
以上图为例：第一步还是需要获得它的硬标签,获得他的初始位置，然后基于这三个初始位置再去和人标注框计算得到软标签，得到真正需要把这个红框所分配到的位置，这时的软标签就叫做细粒度的软标签，但是我们发现中线点和周围四个格子都有接触，因此粗粒度的软标签指的是需要同时考虑这五个位置来做为初始位置去计算软标签。也就是粗标签会允许更多的网格位置

细粒度和粗粒度的区别就是在第一步获得侯选位置时，只考虑这三个网格还是考虑五个网格

网络结构
yolov7
![[Pasted image 20230419183225.png]]
当一张640 * 640的图片输入到网络结构中之后每一层的维度特征的变化

配置文件把网络结构分为两部分 backbone head
![[Pasted image 20230419184256.png]]
![[Pasted image 20230419184313.png]]
![[Pasted image 20230419184334.png]]
![[Pasted image 20230419184704.png]]
![[Pasted image 20230419185314.png]]
![[Pasted image 20230419191939.png]]

![[Pasted image 20230419192014.png]]
![[Pasted image 20230419192836.png]]
左图中 右侧的四个卷积组成了两条支路，而在右边的这个结构中这四个卷积组成了四条之路i  
![[Pasted image 20230419193237.png]]![[Pasted image 20230419194445.png]]![[Pasted image 20230419193640.png]]![[Pasted image 20230419200238.png]]![[Pasted image 20230419194455.png]]
重参数化卷积的参数量会不会增加？
使用RepVGG的重参数化方法后，卷积层的参数量不会增加，而是相对于原来的卷积层减少了。这是因为重参数化方法将原来的卷积层中的卷积核权重和偏置参数分离开来，并且将卷积核权重分解成两部分：一个是固定的低秩卷积核，另一个是学习得到的非线性变换。
这种方法的好处是能够将一个卷积层转化为一个类似于全连接层的形式，这使得卷积层的计算变得更加高效。而且由于使用了低秩卷积核，这些参数的数量会比原来的卷积核数量更少，从而减少了网络的参数量，降低了过拟合的风险。因此，使用RepVGG的重参数化方法可以同时提高网络的计算效率和泛化能力。

标签分配里粗标签和细标签有什么用？
在YOLOv7中，粗标签通常是指物体的类别，而细标签则是指物体的属性或状态，例如物体的颜色、尺寸、形状等。使用粗标签和细标签可以带来以下几个好处：
1.  更准确的检测结果：使用粗标签和细标签可以提供更多的信息来识别物体，从而提高检测的准确性和可靠性。例如，如果对于一个特定的物体类别，还可以标记物体的颜色和尺寸，那么在检测时可以更精确地判断该物体是否符合该类别。
2.  更好的数据管理：使用粗标签和细标签可以更轻松地组织和管理大量数据。通过将不同的标签分配给不同的数据，可以更准确地跟踪和识别每个物体的属性，从而更轻松地管理和分析数据。
3.  更好的可视化：使用粗标签和细标签可以提供更丰富的信息来呈现物体的属性和状态。例如，通过将物体的颜色和尺寸标记为细标签，可以更清楚地展示每个物体的属性，从而更容易地理解和分析数据。
4.  更好的应用场景：通过使用粗标签和细标签，可以将算法应用于更广泛的场景中。例如，在某些场景中，物体的尺寸和颜色可能比物体的类别更重要，因此将这些属性标记为细标签可以提高算法在这些场景中的准确性和可靠性。

模型缩放是怎么做的？
由于增加模型的深度缩放时，计算块的输出宽度也会增加。这种现象会导致后续传输层的输入宽度增大。所以我们对计算块中的深度进行缩放，其余的传输层进行相应的宽度缩放。
重参数化卷积的目的？
在训练时使用相对复杂的结构训练，训练完成后重参数化成一个相对普通的卷积做推断，因此能在不增加推理速度的同时提升模型的训练效果
